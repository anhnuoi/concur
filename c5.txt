n the next chapter, you will learn how to execute algorithms in a concurrent way
that can be divided into phases, for example, a keyword extraction algorithm.
You can implement that algorithm in the following three steps:
1. Step 1 – parse all the documents and extract all the words.
2. Step 2 – calculate the importance of each word on each document.
3. Step 3 – obtain the best keywords.
The main characteristic of these steps is that you must finish one completely
before you can start the next one. Java concurrency API provides the Phaser class
to facilitate the concurrent implementation of these algorithms. It allows you to
synchronize all the tasks involved on it at the end of a phase, so none of them will
start the next one until all have finished the current one.
[ 141 ]
Running Tasks Divided into
Phases – The Phaser Class
The most important element in a concurrent API is the synchronization mechanisms
it offers to the programmer. Synchronization is the coordination of two or more
tasks to get the desired result. You can synchronize the execution of two or more
tasks, when they have to be executed in a predefined order, or synchronize the
access to a shared resource, when only one thread at a time can execute a fragment
of code or modify a block of memory. Java 8 concurrency API provides a lot of
synchronization mechanisms from the basic synchronized keyword or the Lock
interface and their implementations to protect a critical section to the more advanced
CyclicBarrier or CountDownLatch classes that allows you to synchronize the order
of execution of different tasks. In Java 7, the concurrency API introduces the Phaser
class. This class provides a powerful mechanism (phaser) to execute tasks divided
into phases. The task can ask the Phaser class to wait until all other participants
finish the phase. In this chapter, we will cover the following topics:
• An introduction to the Phaser class
• First example – a keyword extraction algorithm
• Second example – a genetic algorithm
Running Tasks Divided into Phases – The Phaser Class
[ 142 ]
An introduction to the Phaser class
The Phaser class is a synchronization mechanism designed to control the execution
of algorithms that can be divided into phases in a concurrent way. If you have a
process with clear defined steps so you have to finish the first one before you can
start the second one and so on, you can use this class to make a concurrent version
of your process. The main characteristics of the Phaser class are:
• The phaser must know the number of tasks it has to control. Java refers to
this as the registration of the participants. A participant can register in a
phaser any time.
• The tasks must inform the phaser when they finish a phase. The phaser will
make that task sleep until all the participants have finished that phase.
• Internally, the phaser saves an integer number that stores the number of
phase changes the phase has made.
• A participant can leave the control of the phaser any time. Java refers to this
as the deregistration of the participants.
• You can execute custom code when the phaser makes a phase change.
• You can control the termination of the phaser. If a phaser is terminated,
no new participants will be accepted and no synchronization between
tasks will be made.
• You can use some methods to know the status and the number of
participants of a phaser.
Registration and deregistration of participants
As we mentioned before, a phaser must know the number of tasks it has to control. It
has to know how many different threads are executing the phase-divided algorithm
to control the simultaneous phase change in a correct way.
Java refers to this process as the registration of participants. The normal situation is
that participants are registered at the beginning of the execution, but a participant
can be registered any time.
You can register a participant using different methods:
• When you create the Phaser object: The Phaser class provides four different
constructors. Two of them are commonly used:
° Phaser(): This constructor creates a phaser with zero participants
° Phaser(int parties): This constructor creates a phaser with the
given number of participants
Chapter 5
[ 143 ]
• Explicitly, using one of these methods:
° bulkRegister(int parties): Register the given number of new
participants at the same time
° register(): Register one new participant
When one of the tasks controlled by the phaser finishes its execution, it must
deregister from the phaser. If you don't do this, the phaser will wait endlessly
for it in the next phase change. To deregister a participant, you can use this
arriveAndDeregister()method. You use this method to indicate the phaser that
this task has finished the current phase and it won't participate in the next phases.
Synchronizing phase changes
The main purpose of the phaser is to allow the implementation of algorithms that
are clearly divided into phases in a concurrent way. None of the tasks can advance
to the next phase until all the tasks have finished the previous phase. The Phaser
class provides three methods to signal that the task finished the phase: arrive(),
arriveAndDeregister(), and arriveAndAwaitAdvance(). If one of the tasks
doesn't call one of these methods, the rest of the participant tasks will be blocked
by the phaser indefinitely. To advance to the next phase, the following methods
are used:
• arriveAndAwaitAdvance(): A task uses this method to indicate to the
phaser that it has finished the current phase and wants to continue with the
next one. The phaser will block the tasks until all the participant tasks have
called one of the synchronization methods.
• awaitAdvance(int phase): A task uses this method to indicate to the
phaser that it wants to wait for the finalization of the current phase if the
number we pass as a parameter and the actual phase of the phaser are equal.
If they aren't equal, this method returns immediately.
Other functionalities
When all the participant tasks have finished the execution of a phase and before they
continue with the next one, the Phaser class executes the onAdvance() method. This
method receives the two following parameters:
• phase: This is the number of the phase that has finished. The first phase is
the number zero
• registeredParties: This indicates the number of participant tasks
Running Tasks Divided into Phases – The Phaser Class
[ 144 ]
If you want to execute some code between two phases, for example, to sort or to
transform some data, you can implement your own phaser extending the Phaser
class and overriding this method.
A phaser can be in two states:
• Active: The phaser enters in this state when it's created and new participants
are registered and continue on it until its termination. When it's in this state,
it accepts new participants and works as it has been explained before.
• Termination: The phaser enters in this state when the onAdvance() method
returns the true value. By default, it returns the true value when all the
participants have been deregistered.
When a phaser is in the termination state, registration
of new participants has no effect and synchronization
methods return immediately.
Finally, the Phaser class provides some methods to get information about the status
and participants in the phaser:
• getRegisteredParties(): This method returns the number of participants
in the phaser
• getPhase(): This method returns the number of the current phase
• getArrivedParties(): This method returns the number of participants
that have finished the current phase
• getUnarrivedParties(): This method returns the number of participants
that haven't finished the current phase
• isTerminated(): This method returns true value if the phaser is in the
termination state and false otherwise
First example – a keyword extraction
algorithm
In this section, you are going to use a phaser to implement a keyword extraction
algorithm. The main purpose of these kinds of algorithms is to extract the words
from a text document or a collection of documents that define the document of the
document inside the collection better. These terms can be used to summarize the
documents, clustering them or to improve the information search process.
Chapter 5
[ 145 ]
The most basic algorithm to extract the keywords of the documents in a collection
(but it's still commonly used nowadays) is based on the TF-IDF measure where:
• TF (short for term frequency) is the number of times that a word appears in
a document.
• DF (short for document frequency) is the number of documents that
contains a word. The IDF (short for inverse document frequency) measures
the information that word provides to distinguish a document from others. If
a word is very common, it's IDF will be low, but if the word appears in only
a few documents, it's IDF will be high.
The TF-IDF of the word t in the document d can be calculated using the
following formula:
, log t d
t
N TF IDF TFxIDF F x
n
  − = =    
The attributes used in the preceding formula can be explained as follows:
• Ft,d is the number of appearances of the word t in the document d
• N is the number of documents in the collection
• nt
 is the number of documents that contain the word t
To obtain the keywords of a document, you can select the words with higher values
of its TF-IDF.
The algorithm you are going to implement will calculate the best keywords in a
document collection executing the following phases:
• Phase 1: Parse all the documents and extract the DF of all the words.
Note that you will only have the exact values once you have parsed
all the documents.
• Phase 2: Calculate the TF-IDF for all the words in all the documents.
Select 10 keywords per document (the 10 words with a higher value
of the TF-IDF measure).
• Phase 3: Obtain a list of the best keywords. We considered that those are
the words that are a keyword of a higher number of documents.
Running Tasks Divided into Phases – The Phaser Class
[ 146 ]
To test the algorithm, we will use the Wikipedia pages with information about movies
as the document collection. We have used the same collection in Chapter 4, Getting Data
from the Tasks – The Callable and Future Interfaces. This collection is formed by 100,673
documents. We have converted each Wikipedia page in a text file. You can download
this document collection with all the information about the book.
You are going to implement two different versions of the algorithm: a basic serial
one and a concurrent one using the Phaser class. After this, we will compare
the execution time of both versions to verify that concurrency provides us with
better performance.
Common classes
Both versions of the algorithm share some common functionality to parse the
documents and to store information about documents, keywords, and words.
The common classes are:
• The Document class that stores the name of the file that contains the
document and the words that form it
• The Word class that stores the string with the word and the measures of that
word (TF, DF, and TF-IDF)
• The Keyword class that stores the string with the word and the number of
documents in which the word is a keyword
• The DocumentParser class that extracts the words for a document
Let's see these classes in more detail.
The Word class
The Word class stores the information about a word. This information includes the
whole word and the measures that affect it, that it's to say, it's TF in a document,
it's global DF, and the resultant TF-IDF.
This class implements the Comparable interface because we're going to sort an array
of words in order to obtain the ones with a higher TF-IDF. Refer to the following code:
public class Word implements Comparable<Word> {
Then, we declare the attributes of the class and implement the getters and setters
(these ones are not included):
 private String word;
 private int tf;
 private int df;
 private double tfIdf;
Chapter 5
[ 147 ]
We have implemented other methods of interest as follows:
• The constructor of the class, which initializes the word (with the word
received as parameter) and the df attribute (with a value of 1).
• The addTf() method, which increments the tf attribute.
• The merge() method that receives a Word object and merges the same
word from two different documents. It sums the tf and df attributes
of both objects.
Then, we implement a special version of the setDf() method. It receives the value of
the df attribute as a parameter and the total number of documents in the collection,
and it calculates the tfIdf attribute:
 public void setDf(int df, int N) {
 this.df = df;
 tfIdf = tf * Math.log(Double.valueOf(N) / df);
 }
Finally, we implement the compareTo() method. We want the words ordered from a
higher to lower tfIdf attribute:
 @Override
 public int compareTo(Word o) {
 return Double.compare(o.getTfIdf(), this.getTfIdf());
 }
}
The Keyword class
The Keyword class stores information about a keyword. This information includes the
whole word and the number of documents in which this word is a keyword.
As occurs with the Word class, it implements the Comparable interface because we're
going to sort an array of keywords to obtain the best keywords:
public class Keyword implements Comparable<Keyword> {
Then, we declare the attributes of the class and implement the methods to establish
and return its values (these ones are not included here):
 private String word;
 private int df;
Running Tasks Divided into Phases – The Phaser Class
[ 148 ]
Finally, we implement the compareTo() method. We want the keywords ordered
from a higher to lower number of documents:
 @Override
 public int compareTo(Keyword o) {
 return Integer.compare(o.getDf(), this.getDf());
 }
}
The Document class
The Document class stores the information about a document of the collection
(remember that our collection has 100,673 documents) that includes the name of the
file and the set of words that forms the document. That set of words, usually named
the vocabulary of the document, is implemented as a HashMap using the whole word
as a string as the key and a Word object as the value:
public class Document {
 private String fileName;
 private HashMap <String, Word> voc;
We have implemented a constructor that creates the HashMap and methods to get
and set the name of the file and to return the vocabulary of the document (these
methods are not included). We also have implemented a method to add a word
in the vocabulary. If the word doesn't exist on it, we add to it. If the word exists
in the vocabulary, we increment the tf attribute of the word. We have used the
computeIfAbsent() method of the voc object. This method inserts the word in the
HashMap if it doesn't exist and then increments the tf using the addTf() method:
 public void addWord(String string) {
 voc.computeIfAbsent(string, k -> new Word(k)).addTf();
 }
}
The HashMap class is not synchronized, but we can use it in our concurrent
application because it will not be shared between different tasks. A Document
object will be generated only by one task, so we won't have race conditions in
our concurrent version derived by the utilization of the HashMap class.
Chapter 5
[ 149 ]
The DocumentParser class
The DocumentParser class reads the content of a text file and converts it into a
Document object. It splits the text into the words and stores them in the Document
object to generate the vocabulary of the class. This class has two static methods.
The first one is the parse() method that receives a string with the path of the file
and returns a Document object. It opens the file and reads it line by line, using the
parseLine() method to convert each line into a sequence of words, and stores
them into the Document class:
public class DocumentParser {
 public static Document parse(String path) {
 Document ret = new Document();
 Path file = Paths.get(path);
 ret.setFileName(file.toString());
 try (BufferedReader reader =
 Files.newBufferedReader(file)) {
 for(String line : Files.readAllLines(file)) {
 parseLine(line, ret);
 }
 } catch (IOException x) {
 x.printStackTrace();
 }
 return ret;
 }
The parseLine() method receives the line to parse and the Document object to store
the words as parameters.
First, it deletes the accents of the line using the Normalizer class and converts it
into lowercase:
 private static void parseLine(String line, Document ret) {
 // Clean string
 line = Normalizer.normalize(line, Normalizer.Form.NFKD);
 line = line.replaceAll("[^\\p{ASCII}]", "");
 line = line.toLowerCase();
Running Tasks Divided into Phases – The Phaser Class
[ 150 ]
Then, we split the line in words using the StringTokenizer class and add those
words to the Document object:
 private static void parseLine(String line, Document ret) {
 // Clean string
 line = Normalizer.normalize(line, Normalizer.Form.NFKD);
 line = line.replaceAll("[^\\p{ASCII}]", "");
 line = line.toLowerCase();
 // Tokenizer
 for(String w: line.split("\\W+")) {
 ret.addWord(w);
 }
 }
}
The serial version
We have implemented the serial version of our keyword algorithm in the
SerialKeywordExtraction class. It defines the main() method you are
going to execute to test the algorithm.
The first step is to declare the following necessary internal variables to execute
the algorithm:
• Two Date objects to measure the execution time
• A string to store the name of the directory that contains the
document collection
• An array of File objects to store the files with the document collection
• A HashMap to store the global vocabulary of the document collection
• A HashMap to store the keywords
• Two int values to measure statistic data about the execution
The following includes the declaration of these variables:
public class SerialKeywordExtraction {
 public static void main(String[] args) {
 Date start, end;
Chapter 5
[ 151 ]
 File source = new File("data");
 File[] files = source.listFiles();
 HashMap<String, Word> globalVoc = new HashMap<>();
 HashMap<String, Integer> globalKeywords = new HashMap<>();
 int totalCalls = 0;
 int numDocuments = 0;
 start = new Date();
Then, we have included the first phase of the algorithm. We parse all the documents
using the parse() method of the DocumentParser class. This method returns
a Document object that contains the vocabulary of that document. We add the
document vocabulary to the global vocabulary using the merge() method of the
HashMap class. If a word doesn't exist, it inserts it in the HashMap. If the word exists,
two word objects are merged together summing the Tf and Df attributes:
 if(files == null) {
 System.err.println("Unable to read the 'data'
 folder");
 return;
 }
 for (File file : files) {
 if (file.getName().endsWith(".txt")) {
 Document doc = DocumentParser.parse
 (file.getAbsolutePath());
 for (Word word : doc.getVoc().values()) {
 globalVoc.merge(word.getWord(), word,
 Word::merge);
 }
 numDocuments++;
 }
 }
 System.out.println("Corpus: " + numDocuments + "
 documents.");
After this phase, the globalVocHashMap class contains all the words of the document
collection with their global TF (the total number of appearances of the word in the
collection) and their DF.
Running Tasks Divided into Phases – The Phaser Class
[ 152 ]
Then, we have included the second phase of the algorithm. We are going to calculate
the keywords of each document using the TF-IDF measure, as we explained before.
We have to parse again each document to generate its vocabulary. We have to do this
because we can't store in memory the vocabularies of 100,673 documents that form
our document collection. If you work with a smaller document collection, you can try
to parse the documents only once and store the vocabularies of all the documents in
memory, but in our case, it's impossible. So, we parse all the documents again, and,
to each word, we update the Df attribute using the values stored in the globalVoc.
We also construct an array with all the words in the document:
 for (File file : files) {
 if (file.getName().endsWith(".txt")) {
 Document doc =
 DocumentParser.parse(file.getAbsolutePath());
 List<Word> keywords = new ArrayList<>(
 doc.getVoc().values());
 int index = 0;
 for (Word word : keywords) {
 Word globalWord =
 globalVoc.get(word.getWord());
 word.setDf(globalWord.getDf(),
 numDocuments);
 }
Now, we have the list of keywords with all the words in the document with their
TF-IDF calculated. We use the sort() method of the Collections class to sort the
list getting the words with a higher value of TF-IDF in the first position. Then we get
the first 10 words of that list to store them in the globalKeywordsHashMap using the
addKeyword() method.
There is no special reason to choose the first 10 words. You can try other options,
as a percentage of the words or a minimum value of the TF-IDF measure, and see
their behavior:
 Collections.sort(keywords);
 int counter = 0;
 for (Word word : keywords) {
 addKeyword(globalKeywords, word.getWord());
 totalCalls++;
 }
 }
 }
Chapter 5
[ 153 ]
Finally, we have included the third phase of our algorithm. We convert the
globalKeywordsHashMap into a list of Keyword objects, use the sort() method
of the Collections class to sort that array getting the keywords with a higher DF
value in the first positions of the list, and write the first 100 words in the console.
Refer to the following code:
 List<Keyword> orderedGlobalKeywords = new ArrayList<>();
 for (Entry<String, Integer> entry :
 globalKeywords.entrySet()) {
 Keyword keyword = new Keyword();
 keyword.setWord(entry.getKey());
 keyword.setDf(entry.getValue());
 orderedGlobalKeywords.add(keyword);
 }
 Collections.sort(orderedGlobalKeywords);
 if (orderedGlobalKeywords.size() > 100) {
 orderedGlobalKeywords =
 orderedGlobalKeywords.subList(0, 100);
 }
 for (Keyword keyword : orderedGlobalKeywords) {
 System.out.println(keyword.getWord() + ": " +
 keyword.getDf());
 }
As in the second phase, there is no special reason to choose the first 100 words.
You can try other options if you want.
To finish the main method, we write the execution time and other statistic data in
the console:
 end = new Date();
 System.out.println("Execution Time: " + (end.getTime() -
 start.getTime()));
 System.out.println("Vocabulary Size: " +
 globalVoc.size());
 System.out.println("Keyword Size: " +
 globalKeywords.size());
 System.out.println("Number of Documents: " +
 numDocuments);
 System.out.println("Total calls: " + totalCalls);
 }
Running Tasks Divided into Phases – The Phaser Class
[ 154 ]
The SerialKeywordExtraction class also includes the addKeyword() method that
updates the information of a keyword in the globalKeywordsHashMap class. If the
word exists, the class updates its DF and if the word doesn't exists, inserts it. Refer
to the following code:
 private static void addKeyword(Map<String, Integer>
 globalKeywords, String word) {
 globalKeywords.merge(word, 1, Integer::sum);
 }
}
The concurrent version
To implement the concurrent version of this example, we have used two different
classes as follows:
• The KeywordExtractionTasks class that implements the tasks that are going
to calculate the keywords in a concurrent way. We are going to execute the
tasks as Thread objects, so this class implements the Runnable interface.
• The ConcurrentKeywordExtraction class that provides the main() method
to execute the algorithm and creates, starts, and waits for the tasks to finish.
Let's see these classes in detail.
The KeywordExtractionTask class
As we mentioned before, this class implements the tasks that are going to calculate
the final keyword list. It implements the Runnable interface, so we can execute them
as a Thread, and internally uses some attributes, most of which are shared between
all the tasks:
• Two ConcurrentHashMap objects to store the global vocabulary and the
global keywords: We use the ConcurrentHashMap because these objects
are going to be updated by all the tasks, so we have to use a concurrent data
structure to avoid race conditions.
Chapter 5
[ 155 ]
• Two ConcurrentLinkedDeque of File objects to store the list of files that
forms the document collection: We use the ConcurrentLinkedDeque class
because all the tasks are going to extract (get and delete) elements of the list
simultaneously, so we have to use a concurrent data structure to avoid race
conditions. If we use a normal List, the same File can be parsed twice by
different tasks. We have two ConcurrentLinkedDeque because we have to
parse the collection of documents twice. As we mentioned before, we parse
the document collection extracting File objects from the data structures, so,
when we have parsed the collection, the data structure will be empty.
• A Phaser object to control the execution of the tasks: As we explained
before, our keyword extraction algorithm is executed in three phases. None
of the tasks advanced to one phase until all the tasks have finished the
previous one. We use the Phaser object to control this. If we don't control
this, we will obtain inconsistent results.
• The final step has to be executed by only one thread: We are going to
distinguish one main task from the others using a Boolean value. These
main tasks will execute that final phase.
• The total number of documents in the collection: We need this value
to calculate the TF-IDF measure.
We have included a constructor to initialize all these attributes:
public class KeywordExtractionTask implements Runnable {
 private ConcurrentHashMap<String, Word> globalVoc;
 private ConcurrentHashMap<String, Integer> globalKeywords;
 private ConcurrentLinkedDeque<File> concurrentFileListPhase1;
 private ConcurrentLinkedDeque<File> concurrentFileListPhase2;
 private Phaser phaser;
 private String name;
 private boolean main;
 private int parsedDocuments;
 private int numDocuments;
 public KeywordExtractionTask(
 ConcurrentLinkedDeque<File> concurrentFileListPhase1,
 ConcurrentLinkedDeque<File> concurrentFileListPhase2,
 Phaser phaser, ConcurrentHashMap<String, Word>
 globalVoc,
Running Tasks Divided into Phases – The Phaser Class
[ 156 ]
 ConcurrentHashMap<String, Integer> globalKeywords,
 int numDocuments, String name, boolean main) {
 this.concurrentFileListPhase1 = concurrentFileListPhase1;
 this.concurrentFileListPhase2 = concurrentFileListPhase2;
 this.globalVoc = globalVoc;
 this.globalKeywords = globalKeywords;
 this.phaser = phaser;
 this.main = main;
 this.name = name;
 this.numDocuments = numDocuments;
 }
The run() method implements the algorithm with its three phases. First, we call
the arriveAndAwaitAdvance() method of the phaser to wait for the creation of
the other tasks. All the tasks will start their execution at the same moment. Then, as
we explained in the serial version of the algorithm, we parse all the documents and
build the globalVocConcurrentHashMap class with all the words and their global TF
and DF values. To complete phase one, we call again the arriveAndAwaitAdvance()
method to wait for the finalization of the other tasks before the execution of the
second phase:
 @Override
 public void run() {
 File file;
 // Phase 1
 phaser.arriveAndAwaitAdvance();
 System.out.println(name + ": Phase 1");
 while ((file = concurrentFileListPhase1.poll()) != null) {
 Document doc =
 DocumentParser.parse(file.getAbsolutePath());
 for (Word word : doc.getVoc().values()) {
 globalVoc.merge(word.getWord(), word,
 Word::merge);
 }
 parsedDocuments++;
 }
 System.out.println(name + ": " + parsedDocuments + "
 parsed.");
 phaser.arriveAndAwaitAdvance();
Chapter 5
[ 157 ]
As you can see, to get the File objects to process, we use the poll() method of the
ConcurrentLinkedDeque class. This method retrieves and removes the first element
of Deque, so the next task will obtain a different file to parse, and no file will be
parsed twice.
The second phase calculates the globalKeywords structure, as we explained in
the serial version of the algorithm. First, calculate the best 10 keywords of every
document and then insert them in the ConcurrentHashMap class. The code is the same
as in the serial version changing the serial data structures for the concurrent ones:
 // Phase 2
 System.out.println(name + ": Phase 2");
 while ((file = concurrentFileListPhase2.poll()) != null) {
 Document doc =
 DocumentParser.parse(file.getAbsolutePath());
 List<Word> keywords = new
 ArrayList<>(doc.getVoc().values());
 for (Word word : keywords) {
 Word globalWord = globalVoc.get(word.getWord());
 word.setDf(globalWord.getDf(), numDocuments);
 }
 Collections.sort(keywords);
 if(keywords.size() > 10) keywords =
 keywords.subList(0, 10);
 for (Word word : keywords) {
 addKeyword(globalKeywords, word.getWord());
 }
 }
 System.out.println(name + ": " + parsedDocuments + "
 parsed.");
The final phase will be different for the main task and for the others. The main task
uses the arriveAndAwaitAdvance() method of the Phaser class to wait for the
finalization of the second phase of all the tasks before writing the best 100 keywords
of the whole collection in the console. Finally, it uses the arriveAndDeregister()
method to deregister from the phaser.
The rest of the tasks use the arriveAndDeregister() method to mark the finalization
of the second phase, deregister from the phaser, and finish their execution.
Running Tasks Divided into Phases – The Phaser Class
[ 158 ]
When all the tasks have finished their work, all of them have deregistered
themselves from the phaser. The phaser will have zero parties, and it will
enter the termination state:
 if (main) {
 phaser.arriveAndAwaitAdvance();
 Iterator<Entry<String, Integer>> iterator =
 globalKeywords.entrySet().iterator();
 Keyword orderedGlobalKeywords[] = new
 Keyword[globalKeywords.size()];
 int index = 0;
 while (iterator.hasNext()) {
 Entry<String, AtomicInteger> entry =
 iterator.next();
 Keyword keyword = new Keyword();
 keyword.setWord(entry.getKey());
 keyword.setDf(entry.getValue().get());
 orderedGlobalKeywords[index] = keyword;
 index++;
 }
 System.out.println("Keyword Size: " +
 orderedGlobalKeywords.length);
 Arrays.parallelSort(orderedGlobalKeywords);
 int counter = 0;
 for (int i = 0; i < orderedGlobalKeywords.length;
 i++){
 Keyword keyword = orderedGlobalKeywords[i];
 System.out.println(keyword.getWord() + ": " +
 keyword.getDf());
 counter++;
 if (counter == 100) {
 break;
 }
 }
 }
 phaser.arriveAndDeregister();
 System.out.println("Thread " + name + " has finished.");
 }
Chapter 5
[ 159 ]
The ConcurrentKeywordExtraction class
The ConcurrentKeywordExtraction class initializes the shared objects, creates
the tasks, executes them, and waits for its finalization. It implements the main()
method that can receive an optional parameter. By default, we are doing the number
of tasks determined by the availableProcessors() method of the Runtime class
that returns the number of hardware threads available to the Java Virtual Machine
(JVM). If we receive a parameter, we convert it into an integer and use it as a
multiplier of the number of available processors to determine the number of
tasks we are going to create.
First, we initialize all the necessary data structures and parameters. To fill the two
ConcurrentLinkedDeque structures, we use the listFiles() method of the File
class to get an array of File objects with the files that end with the txt suffix.
We also create the Phaser object using the constructor without parameters, so all the
tasks must register themselves in the phaser explicitly. Refer to the following code:
public class ConcurrentKeywordExtraction {
 public static void main(String[] args) {
 Date start, end;
 ConcurrentHashMap<String, Word> globalVoc = new
 ConcurrentHashMap<>();
 ConcurrentHashMap<String, Integer> globalKeywords = new
 ConcurrentHashMap<>();
 start = new Date();
 File source = new File("data");
 File[] files = source.listFiles(f ->
 f.getName().endsWith(".txt"));
 if (files == null) {
 System.err.println("The 'data' folder not found!");
 return;
 }
 ConcurrentLinkedDeque<File> concurrentFileListPhase1 = new
 ConcurrentLinkedDeque<>(Arrays.asList(files));
 ConcurrentLinkedDeque<File> concurrentFileListPhase2 = new
 ConcurrentLinkedDeque<>(Arrays.asList(files));
 int numDocuments = files.length();
 int factor = 1;
 if (args.length > 0) {
Running Tasks Divided into Phases – The Phaser Class
[ 160 ]
 factor = Integer.valueOf(args[0]);
 }
 int numTasks = factor *
 Runtime.getRuntime().availableProcessors();
 Phaser phaser = new Phaser();
 Thread[] threads = new Thread[numTasks];
 KeywordExtractionTask[] tasks = new
 KeywordExtractionTask[numTasks];
Then, we create the first task with the main parameter to true and the rest with the
main parameter to false. After the creation of each task, we use the register()
method of the Phaser class to register a new participant in the phaser as follows:
 for (int i = 0; i < numTasks; i++) {
 tasks[i] = new
 KeywordExtractionTask(concurrentFileListPhase1,
 concurrentFileListPhase2, phaser, globalVoc,
 globalKeywords, concurrentFileListPhase1.size(),
 "Task" + i, i==0);
 phaser.register();
 System.out.println(phaser.getRegisteredParties() + "
 tasks arrived to the Phaser.");
 }
Then, we create and start the thread objects that run the tasks and wait for
its finalization:
 for (int i = 0; i < numTasks; i++) {
 threads[i] = new Thread(tasks[i]);
 threads[i].start();
 }
 for (int i = 0; i < numTasks; i++) {
 try {
 threads[i].join();
 } catch (InterruptedException e) {
 e.printStackTrace();
 }
 }
Chapter 5
[ 161 ]
Finally, we write some statistic information about the execution in the console,
including the execution time:
 System.out.println("Is Terminated: " +
 phaser.isTerminated());
 end = new Date();
 System.out.println("Execution Time: " + (end.getTime() -
 start.getTime()));
 System.out.println("Vocabulary Size: " +
 globalVoc.size());
 System.out.println("Number of Documents: " +
 numDocuments);
 }
}
Comparing the two solutions
Let's compare the serial and concurrent versions of our keyword extraction 100,673
documents. We have executed the examples using the JMH framework (http://
openjdk.java.net/projects/code-tools/jmh/) that allows you to implement
micro benchmarks in Java. Using a framework for benchmarking is a better
solution that simply measures time using methods such as currentTimeMillis()
or nanoTime(). We have executed them 10 times in a computer with a four-core
processor and calculate the medium execution time of those 10 times.
Algorithm Factor Execution time (seconds)
Serial N/A 194.45
Concurrent 1 64.52
2 65.55
3 68,23
We can draw the following conclusions:
• The concurrent version of the algorithm increases the performance of the
serial version.
• If we use more tasks than the number of the available hardware threads,
we don't get a better result. Just a little worse because of the extra
synchronization work the phaser must do.
Running Tasks Divided into Phases – The Phaser Class
[ 162 ]
We compare the concurrent and serial versions of the algorithm calculating the
speed-up using the following formula:
194.28 3.01
64.52
serial
concurrent
T S
T = = =
The second example – a genetic
algorithm
Genetic algorithms are adaptive heuristic search algorithms based on the natural
selection principles use to generate good solutions to optimization and search
problems. They work with possible solutions to a problem named individuals or
phenotypes. Each individual has a representation formed by a set of properties
named chromosomes. Normally, the individuals are represented by a sequence
of bits, but you can choose the representation that better fits your problem.
You also need a function to determine whether a solution is good or bad named
fitness function. The main objective of the genetic algorithm is to find a solution
that maximizes or minimizes that function.
The genetic algorithm starts with a set of possible solutions to the problem. This
set of possible solutions is named the population. You can generate this initial set
randomly or use some kind of heuristic function to obtain better initial solutions.
Once you have the initial population, you begin an iterative process with three
phases. Each step of that iterative process is called a generation. The phases of
each generation are:
• Selection: You select the better individuals of your population. These are
the individuals with a better value in the fitness function.
• Crossover: You cross the individuals selected in the previous step to generate
the new individuals that form the new generation. This operation takes two
individuals and generates two new individuals. The implementation of this
operation depends on the problem you want to solve and the representation
of the individuals you have chosen.
• Mutation: You can apply a mutation operator to alter the values of an
individual. Normally, you will apply that operation to a very low number
of individuals. While mutation is a very important operation to find a good
solution, we don't apply it to simplify our example.
Chapter 5
[ 163 ]
You repeat these three operations until you meet your finish criteria. These finish
criteria can be:
• A fixed number of generations
• A predefined value of the fitness function
• A solution that meets the predefined criteria is found
• A time limit
• A manual stop
Normally, you will store the best individual you have found across the process
outside of the population. This individual will be the solution proposed by the
algorithm, and normally, it's going to be a better solution, as we generate new
generations.
In this section, we are going to implement a genetic algorithm to solve the
well-known Travel Salesman Problem (TSP). In this problem, you have a set of
cities and the distances between them, and you want to find an optimal route to
go through all the cities minimizing the total distance of the travel. As per other
examples, we have implemented a serial version and a concurrent one using the
Phaser class. The main characteristics of a genetic algorithm applied to the TSP
problems are:
• Individuals: An individual represents the traversal order of the cities.
• Crossover: You have to create valid solutions after the crossover operation.
You must visit each city only once.
• Fitness function: The main objective of the algorithm is to minimize the total
distance to travel across the cities.
• Finish criteria: We are going to execute the algorithm a predefined number
of generations.
For example, you can have a distance matrix with four cities as shown in the
following table:
City 1 City 2 City 3 City 4
City 1 0 11 6 9
City 2 7 0 8 2
City 3 7 3 0 3
City 4 10 9 4 0
Running Tasks Divided into Phases – The Phaser Class
[ 164 ]
This means that the distance between city 2 and city 1 is 7, but the distance between
city 1 and city 2 is 11. An individual can be (2,4,3,1) and its fitness function is the sum
of the distances between 2 and 4, 4 and 3, 3 and 1, and 1 and 2, that is, 2+4+7+11=24.
If you want to make the crossover between the individuals (1,2,3,4) and (1,3,2,4), you
can't generate the individual (1,2,2,4) because you are visiting the city 2 twice. You
can generate the individuals (1,2,4,3) and (1,3,4,2).
To test the algorithm, we have used two examples of the City Distance Datasets
(http://people.sc.fsu.edu/~jburkardt/datasets/cities/cities.html)
with 15 (lau15_dist) and 57 (kn57_dist) cities, respectively.
Common classes
Both versions use the following three common classes:
• The DataLoader class that loads the distance matrix from a file. We don't
include the code of this class here. It has a static method that receives the
name of the file and returns an int[][] matrix with the distances between
the cities. The distances are stored in a csv file (we have made a little
transformation in the original format), so it's easy to make the conversion.
• The Individual class stores the information of an individual of the
population (a possible solution to the problem). To represent each individual,
we have chosen an array of integer values that stores the order in which you
visit the different cities.
• The GeneticOperators class implements the crossover, selection and
evaluation of the population or an individual.
Let's see the details of the Individual and GeneticOperators classes.
The Individual class
This class stores each possible solution to our TSP problem. We call each possible
solution, an individual, and its representation chromosomes. In our case, we
represent each possible solution as an array of integers. That array contains the order
in which our salesman will go through the cities. This class also has an integer value
to store the result of the fitness function. We have the following code:
public class Individual implements Comparable<Individual> {
 private Integer[] chromosomes;
 private int value;
Chapter 5
[ 165 ]
We have included two constructors. The first one receives the number of cities you
must visit, and we create an empty array. The other receives an Individual object
and copies its chromosomes as follows:
 public Individual(int size) {
 chromosomes=new Integer[size];
 }
 public Individual(Individual other) {
 chromosomes = other.getChromosomes().clone();
 }
We have also implemented the compareTo() method to compare two individuals
using the result of the fitness function:
 @Override
 public int compareTo(Individual o) {
 return Integer.compare(this.getValue(), o.getValue());
 }
Finally, we have included methods to get and set the values of the attributes.
The GeneticOperators class
This is a complex class because it implements the internal logic of the genetic
algorithm. It provides methods to make the initialization, selection, crossover, and
evaluation operations as were introduced at the beginning of this section. We are
going to describe only the methods provided by this class, but not how they are
implemented to avoid your unnecessary complexity. You can get the source code
of the example to analyze the implementation of the methods.
The methods provided by this class are:
• initialize(int numberOfIndividuals, int size): This creates a new
population. The number of individuals of that population will be determined
by the numberOfIndividuals parameter. The number of chromosomes
(cities in our case) will be determined by the size parameter. It returns an
array of Individual objects. It uses the method initialize(Integer[]) to
initialize each Individual.
• initialize(Integer[] chromosomes): It initializes the chromosomes of an
individual in a random way. It generates valid individuals (you have to visit
each city only once).
Running Tasks Divided into Phases – The Phaser Class
[ 166 ]
• selection(Individual[] population): This method implements the
selection operation to get the best individuals of a population. It returns
that individuals in an array. The size of that array will be the half of the
population size. You can test other criteria to determine the number of
the selected individuals. We select the individuals with the best fit function.
• crossover(Individual[] selected, int numberOfIndividuals,
int size): This method receives the selected individuals of a generation
as a parameter and generates the population of the next generation using
the crossover operation. The number of individuals of the next generation
will be determined by the parameter of the same name. The number of
chromosomes of each individual will be determined by the size parameter.
It uses the method crossover (Individual, Individual, Individual,
Individual) to generate two new individuals from two selected ones.
• crossover(Individual parent1, Individual parent2, Individual
individual1, Individual individual2): This method performs the
crossover operation taking the parent1 and parent2 individuals to generate
the individual1 and individual2 individuals of the next generation.
• evaluate(Individual[] population, int [][] distanceMatrix): This
applies the fitness function to all the individuals of the population using the
distance matrix it receives as a parameter. Finally, it sorts the population
from the best to worst solution. It uses the method evaluate (Individual,
int[][]) to evaluate each individual.
• evaluate(Individual individual, int[][] distanceMatrix):
This applies the fitness function to one individual.
With this class and its methods, you have all you need to implement a genetic
algorithm to solve the TSP problem.
The serial version
We have implemented the serial version of the algorithm with the following
two classes:
• The SerialGeneticAlgorithm class that implements the algorithm
• The SerialMain class that executes the algorithm with the input parameters
and measures the execution time
Let's analyze both classes in detail.
Chapter 5
[ 167 ]
The SerialGeneticAlgorithm class
This class implements the serial version of our genetic algorithm. Internally, it uses
the following four attributes:
• The distance matrix with the distances between all the cities
• The number of generations
• The number of individuals in the population
• The number of chromosomes in each individual
The class also has a constructor to initialize all the attributes:
 private int[][] distanceMatrix;
 private int numberOfGenerations;
 private int numberOfIndividuals;
 private int size;
 public SerialGeneticAlgorithm(int[][] distanceMatrix,
 int numberOfGenerations, int numberOfIndividuals) {
 this.distanceMatrix = distanceMatrix;
 this.numberOfGenerations = numberOfGenerations;
 this.numberOfIndividuals = numberOfIndividuals;
 size = distanceMatrix.length;
 }
The main method of the class is the calculate() method. First, use the
initialize() method to create the initial population. Then, evaluate the initial
population and get its best individual as the first solution of the algorithm:
 public Individual calculate() {
 Individual best;
 Individual[] population = GeneticOperators.initialize(
 numberOfIndividuals, size);
 GeneticOperators.evaluate(population, distanceMatrix);
 best = population[0];
Running Tasks Divided into Phases – The Phaser Class
[ 168 ]
Then, it executes a loop determined by the numberOfGenerations attribute. In each
cycle, it uses the selection() method to obtain the selected individuals, use the
crossover() method to calculate the next generation, evaluate this new generation,
and if the best solution of the new generation is better than the best individual until
now, we replace it. When the loop finishes, we return the best individual as the
solution proposed by the algorithm:
 for (int i = 1; i <= numberOfGenerations; i++) {
 Individual[] selected =
 GeneticOperators.selection(population);
 population = GeneticOperators.crossover(selected,
 numberOfIndividuals, size);
 GeneticOperators.evaluate(population, distanceMatrix);
 if (population[0].getValue() < best.getValue()) {
 best = population[0];
 }
 }
 return best;
 }
The SerialMain class
This class executes the genetic algorithm for the two datasets used in this
section—the lau15 with 15 cities and the kn57 with 57 cities.
The main() method must receive two parameters. The first one is the number
of generations we want to create, and the second parameter is the number of
individuals we want to have in each generation:
public class SerialMain {
 public static void main(String[] args) {
 Date start, end;
 int generations = Integer.valueOf(args[0]);
 int individuals = Integer.valueOf(args[1]);
Chapter 5
[ 169 ]
For each example, we load the distance matrix using the load() method of
the DataLoader class, create the SerialGeneticAlgorith object, execute the
calculate() method measuring the execution time, and write the execution time
and the result in the console:
 for (String name : new String[] { "lau15_dist", "kn57_dist" })
 {
 int[][] distanceMatrix = DataLoader.load(Paths.get("data",
 name + ".txt"));
 SerialGeneticAlgorithm serialGeneticAlgorithm = new
 SerialGeneticAlgorithm(distanceMatrix, generations,
 individuals);
 start = new Date();
 Individual result =
 serialGeneticAlgorithm.calculate();
 end = new Date();
 System.out.println
 ("=======================================");
 System.out.println("Example:"+name);
 System.out.println("Generations: " + generations);
 System.out.println("Population: " + individuals);
 System.out.println("Execution Time: " + (end.getTime() -
 start.getTime()));
 System.out.println("Best Individual: " + result);
 System.out.println("Total Distance: " +
 result.getValue());
 System.out.println
 ("=======================================");
 }
The concurrent version
We have implemented the concurrent version of the genetic algorithm
different classes:
• The SharedData class stores all the objects that will be shared between
the tasks
• The GeneticPhaser class extends the Phaser class and overrides its
onAdvance() method to execute code when all the tasks finish a phase
• The ConcurrentGeneticTask class implements the tasks that will implement
the phases of the genetic algorithm
• The ConcurrentGeneticAlgorithm class will implement the concurrent
version of the genetic algorithm using the previous classes
• The ConcurrentMain class will test the concurrent version of the genetic
algorithm in our two datasets
Running Tasks Divided into Phases – The Phaser Class
[ 170 ]
Internally, the ConcurrentGeneticTask class will execute three phases. The first
one is the selection phase and will only be executed by one task. The second one is
the crossover phase where all the tasks will construct the new generation using the
selected individuals, and the last phase is the evaluation phase where all the tasks
will evaluate the individuals of the new generation.
Let's see in detail each of those classes.
The SharedData class
As we mentioned before, this class contains all the objects shared by the tasks.
This include the following:
• The population array with all the individuals of a generation.
• The selected array with the selected individuals.
• An atomic integer called index. This is the only thread-safe object used to
know the index of the individual a task has to generate or process.
• The best individual of all the generations that will be returned as the solution
of the algorithm.
• The distance matrix with the distances between the cities.
All these objects will be shared by all the threads, but we only need to use one
concurrent data structure. This is the only attribute that will be effectively shared by
all the tasks. The rest of the objects will be only read (the distance matrix), or each
task will access a different part of the object (the population and selected arrays), so
we don't need to use concurrent data structures or synchronization mechanisms to
avoid race conditions:
public class SharedData {
 private Individual[] population;
 private Individual selected[];
 private AtomicInteger index;
 private Individual best;
 private int[][] distanceMatrix;
}
This class also includes the getters and setters to get and establish the values of
these attributes.
Chapter 5
[ 171 ]
The GeneticPhaser class
We need to execute code on the phase changes of our tasks, so we have to implement
our own phaser and override the onAdvance() method that is executed after all the
parties have finished a phase and before they begin the execution of the next one.
The GeneticPhaser class implements this phaser. It stores the SharedData object
to work with it and receives it as a parameter to the constructor:
public class GeneticPhaser extends Phaser {
 private SharedData data;
 public GeneticPhaser(int parties, SharedData data) {
 super(parties);
 this.data=data;
 }
The onAdvance() method will receive the number of the phase to the phaser and the
number of registered parties as parameters. The phaser internally stores the number
of the phase as an integer that grows sequentially with every change of phase. On the
contrary, our algorithm has only three phases that will be executed a lot of times. We
have to convert the phaser phase number to the genetic algorithm phase number to
know if the tasks are going to execute the selection, crossover, or evaluation phases.
To do this, we calculate the remainder between the phase number of the phaser and
three as follows:
 protected boolean onAdvance(int phase, int registeredParties) {
 int realPhase=phase%3;
 if (registeredParties>0) {
 switch (realPhase) {
 case 0:
 case 1:
 data.getIndex().set(0);
 break;
 case 2:
 Arrays.sort(data.getPopulation());
 if (data.getPopulation()[0].getValue() <
 data.getBest().getValue()) {
 data.setBest(data.getPopulation()[0]);
 }
 break;
 }
 return false;
 }
 return true;
 }
Running Tasks Divided into Phases – The Phaser Class
[ 172 ]
If the remainder is zero, the tasks have finished the selection phase and are going
to execute the crossover phase. We initialize the index object with the value zero.
If the remainder is one, the tasks have finished the crossover phase and are going
to execute the evaluation phase. We initialize the index object with the value zero.
Finally, if the remainder is two, the tasks have finished the evaluation phase and are
going to start again with the selection phase. We sort the population based on the
fitness function and update if necessary the best individual.
Take into account that this method will only be executed by one thread independently
of the tasks. It will be executed in the thread of the task, which was the last to finish
the previous phase (inside the arriveAndAwaitAdvance() call). The rest of the tasks
will be sleeping and waiting for the phaser.
The ConcurrentGeneticTask class
This class implements the tasks that collaborate to execute the genetic algorithm.
They execute the three phases (selection, crossover, and evaluation) of the algorithm.
The selection phase will be executed by only one task (we called it the main task)
while the rest of the phases will be executed by all the tasks.
Internally, it uses four attributes:
• A GeneticPhaser object to synchronize the tasks at the end of each phase
• A SharedData object to access the shared data
• The number of generations it has to calculate
• The Boolean flag that indicates whether it is the main task or not
All these attributes are initialized in the constructor of the class:
public class ConcurrentGeneticTask implements Runnable {
 private GeneticPhaser phaser;
 private SharedData data;
 private int numberOfGenerations;
 private boolean main;
 public ConcurrentGeneticTask(GeneticPhaser phaser, int
 numberOfGenerations, boolean main) {
 this.phaser = phaser;
 this.numberOfGenerations = numberOfGenerations;
 this.main = main;
 this.data = phaser.getData();
 }
Chapter 5
[ 173 ]
The run() method implements the logic of the genetic algorithm. It has a
loop to generate the specified generations. As we mentioned before, only the
main task will execute the selection phase. The rests of the tasks will use the
arriveAndAwaitAdvance() method to wait for the finalization of this phase.
Refer to the following code:
 @Override
 public void run() {
 Random rm = new Random(System.nanoTime());
 for (int i = 0; i < numberOfGenerations; i++) {
 if (main) {
 data.setSelected(GeneticOperators.selection(data
 .getPopulation()));
 }
 phaser.arriveAndAwaitAdvance();
The second phase is the crossover phase. We use the AtomicInteger variable index
stored in the SharedData class to get the next position in the population array each
task will calculate. As we mentioned before, the crossover operation generates two
new individuals, so each task first reserves two positions in the population array. For
this purpose, we use the getAndAdd(2) method that returns the actual value of the
variable and increments its value by two units. It's an atomic variable, so we don't
have to use any synchronization mechanism. It's inherent to the atomic variables.
Refer to the following code:
 // Crossover
 int individualIndex;
 do {
 individualIndex = data.getIndex().getAndAdd(2);
 if (individualIndex < data.getPopulation().length)
 {
 int secondIndividual = individualIndex++;
 int p1Index = rm.nextInt
 (data.getSelected().length);
 int p2Index;
 do {
 p2Index = rm.nextInt
 (data.getSelected().length);
 } while (p1Index == p2Index);
 Individual parent1 = data.getSelected()
 [p1Index];
Running Tasks Divided into Phases – The Phaser Class
[ 174 ]
 Individual parent2 = data.getSelected()
 [p2Index];
 Individual individual1 = data.getPopulation()
 [individualIndex];
 Individual individual2 = data.getPopulation()
 [secondIndividual];
 GeneticOperators.crossover(parent1, parent2,
 individual1, individual2);
 }
 } while (individualIndex <
 data.getPopulation().length);
 phaser.arriveAndAwaitAdvance();
When all the individuals of the new population have been generated, the tasks use
the arriveAndAwaitAdvance() method to synchronize the end of the phase.
The last phase is the evaluation phase. We use the AtomicInteger index again. Each
task gets the actual value of the variable, which represents the position of an individual
in the population, and increments its value using the getAndIncrement() value.
Once all the individuals have been evaluated, we use the arriveAndAwaitAdvance()
method to synchronize the end of this phase. Remember that, when all the tasks
have finished this phase, the GeneticPhaser class will execute the code that sorts the
population array and updates, if necessary, the best individual variable as follows:
 // Evaluation
 do {
 individualIndex =
 data.getIndex().getAndIncrement();
 if (individualIndex < data.getPopulation().length)
 {
 GeneticOperators.evaluate(data.getPopulation()
 [individualIndex], data.getDistanceMatrix());
 }
 } while (individualIndex <
 data.getPopulation().length);
 phaser.arriveAndAwaitAdvance();
 }
 phaser.arriveAndDeregister();
 }
Finally, when all the generations have been calculated, the tasks use the
arriveAndDeregister() method to indicate the end of its execution,
so the phaser will enter in its finalization state.
Chapter 5
[ 175 ]
The ConcurrentGeneticAlgorithm class
This class is the external interface of the genetic algorithm. Internally, it creates,
starts, and waits for the finalization of the tasks that calculate the different
generations. It uses four attributes: the number of generations, the number of
individuals in each generation, the number of chromosomes of each individual,
and the distance matrix as follows:
public class ConcurrentGeneticAlgorithm {
 private int numberOfGenerations;
 private int numberOfIndividuals;
 private int[][] distanceMatrix;
 private int size;
 public ConcurrentGeneticAlgorithm(int[][] distanceMatrix, int
 numberOfGenerations, int numberOfIndividuals) {
 this.distanceMatrix=distanceMatrix;
 this.numberOfGenerations=numberOfGenerations;
 this.numberOfIndividuals=numberOfIndividuals;
 size=distanceMatrix.length;
 }
The calculate() method executes the genetic algorithm and returns the best
individual. First, it creates the initial population using the initialize() method,
evaluates that population, and creates and initialize a SharedData object with all
the necessary data as follows:
 public Individual calculate() {
 Individual[] population=
 GeneticOperators.initialize(numberOfIndividuals,size);
 GeneticOperators.evaluate(population,distanceMatrix);
 SharedData data=new SharedData();
 data.setPopulation(population);
 data.setDistanceMatrix(distanceMatrix);
 data.setBest(population[0]);
Running Tasks Divided into Phases – The Phaser Class
[ 176 ]
Then, it creates the tasks. We use the number of available hardware threads of the
computer, returned by the method availableProcessors() of the Runtime class as
the number of tasks we are going to create. We also create a GeneticPhaser object
to synchronize the execution of those tasks as follows:
 int numTasks=Runtime.getRuntime().availableProcessors();
 GeneticPhaser phaser=new GeneticPhaser(numTasks,data);
 ConcurrentGeneticTask[] tasks=new
 ConcurrentGeneticTask[numTasks];
 Thread[] threads=new Thread[numTasks];
 tasks[0]=new ConcurrentGeneticTask(phaser,
 numberOfGenerations, true);
 for (int i=1; i< numTasks; i++) {
 tasks[i]=new ConcurrentGeneticTask(phaser,
 numberOfGenerations, false);
 }
Then, we create the Thread objects to execute the tasks, start them, and wait for
their finalization. Finally, we return the best individual stored in the ShareData
object as follows:
 for (int i=0; i<numTasks; i++) {
 threads[i]=new Thread(tasks[i]);
 threads[i].start();
 }
 for (int i=0; i<numTasks; i++) {
 try {
 threads[i].join();
 } catch (InterruptedException e) {
 e.printStackTrace();
 }
 }
 return data.getBest();
 }
}
The ConcurrentMain class
This class executes the genetic algorithm for the two datasets used in this
section—the lau15 with 15 cities and the kn57 with 57 cities. Its code is analogous
to the SerialMain class, but using the ConcurrentGeneticAlgorithm instead of
SerialGeneticAlgorithm.
Chapter 5
[ 177 ]
Comparing the two solutions
Now it's time to test both solutions and see which of them has the better
performance. As we mentioned before, we have used two datasets from the City
Distance Datasets (http://people.sc.fsu.edu/~jburkardt/datasets/cities/
cities.html)—the lau15 with 15 cities and the kn57 with 57 cities. We also have
tested different sizes for the population (100, 1,000, and 10,000 individuals) and the
different number of generations (10, 100, and 1,000). To test the algorithm, we have
executed the examples using the JMH framework (http://openjdk.java.net/
projects/code-tools/jmh/) that allows you to implement micro benchmarks in
Java. Using a framework for benchmarking is a better solution that simply measures
time using such methods as currentTimeMillis() or nanoTime(). We have
executed them 10 times on a computer with a four-core processor and calculated the
medium execution time of those 10 times.
The Lau15 dataset
The execution times (in milliseconds) for the first dataset are:
Population
100 1,000 10,000
Generations Serial Concurrent Serial Concurrent Serial Concurrent
10 8.42 13.309 30.783 36.395 182.213 99.728
100 25.848 29.292 135.562 69.257 1488.457 688.840
1,000 117.929 71.771 1134.983 420.145 11810.518 4102.72
The Kn57 dataset
The execution times (in milliseconds) for the second dataset are:
Population
100 1,000 10,000
Generations Serial Concurrent Serial Concurrent Serial Concurrent
10 19.205 22.246 80.509 63.370 758.235 300.669
100 75.129 63.815 680.548 225.393 7406.392 2561.219
1,000 676.390 243.572 6796.780 2159.124 75315.885 26825.115
Running Tasks Divided into Phases – The Phaser Class
[ 178 ]
Conclusions
The behavior of the algorithms is similar to both datasets. You can see that as
we have a low number of individuals and generations the serial versions of the
algorithm have better execution times, but when the number of individuals or the
number of generations grow, the concurrent version has a better throughput. For
example, for the kn57 dataset with 1,000 generations and 10,000 individuals the
speed-up is:
75315.885 2.80
26825.115
serial
concurrent
T S
T = = =
Summary
In this chapter, we explained one of the most powerful synchronization mechanisms
provided by the Java concurrency API: the phaser. Its main objective is to provide
synchronization between tasks that execute algorithms divided into phases. None of
the tasks can begin the execution of a phase before the rest of the tasks have finished
the previous one.
The phaser has to know how many tasks have to be synchronized. You have
to register your tasks in the phaser using the constructor, the bulkRegister()
method or the register() method.
Tasks can synchronize with the phaser in different ways. The most common are
indicating to the phaser that it has finished the execution of one phase and wants
to continue with the next one with the arriveAndAwaitAdvance() method. This
method will sleep the thread until the rest of the tasks have finished the actual phase.
But there are other methods you can use to synchronize your tasks. The method
arrive() is used to notify to the phaser that you have finished the current phase,
but you don't wait for the rest of the tasks (be very careful using this method). The
arriveAndDeregister() method is used to notify the phaser that you have finished
the current phase and you don't want to continue in the phaser (normally, because
you have finished your job). Finally, the awaitAdvance() method can be used to
wait for the finalization of the current phase.
You can control the phase change and execute code after all the tasks have finished
the current phase and before they start the new one using the onAdvance()
method. This method is called between the executions of two phases and receives as
parameters the number of the phase and the number of participants in the phaser.
You can extend the Phaser class and override this method to execute code between
two phases.
Chapter 5
[ 179 ]
A phaser can be in two states: active, when it is synchronizing tasks and in the
termination state, when it has finished its job. A phaser will enter in the termination
state when all the participants call the arriveAndDeregister() method or when the
onAdvance() method returns the true value (by default, it always return false).
When a Phaser class is in the termination state, it won't accept new participants
and the synchronization methods will always return immediately.
We used the Phaser class to implement two algorithms: a keyword extraction
algorithm and a genetic algorithm. In both cases, we got an important increase
of throughput against the serial version of those algorithms.
In the next chapter, you will learn how to use another Java concurrency framework
to solve special kind of problems. It's the Fork/Join framework, which has been
developed to execute in a concurrent way those problems that can be solved using
the divide and conquer algorithm. It's based in an executor with a special
work-stealing algorithm that maximizes the performance of the executor.
